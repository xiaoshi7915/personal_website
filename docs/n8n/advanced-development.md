---
sidebar_position: 3
---

# é«˜çº§å¼€å‘æŒ‡å—

æœ¬ç« å°†æ·±å…¥æ¢è®¨n8nå·¥ä½œæµçš„é«˜çº§å¼€å‘æŠ€æœ¯ï¼Œä»n8nå¹³å°çš„æ·±åº¦è§£æå¼€å§‹ï¼Œåˆ°è‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘ã€å¤æ‚å·¥ä½œæµè®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–å’Œä¼ä¸šçº§éƒ¨ç½²ç­‰é«˜çº§ä¸»é¢˜ã€‚

## n8nå¹³å°æ·±åº¦è§£æ

### ä»€ä¹ˆæ˜¯n8nï¼Ÿ

n8nï¼ˆå‘éŸ³ä¸º "n-eight-n"ï¼‰æ˜¯ä¸€ä¸ªå¼€æºçš„ã€å¯è§†åŒ–çš„å·¥ä½œæµè‡ªåŠ¨åŒ–å¹³å°ï¼Œä¸“é—¨è®¾è®¡ç”¨äºè¿æ¥å„ç§æœåŠ¡å’Œåº”ç”¨ç¨‹åºã€‚å®ƒé‡‡ç”¨äº†"å…¬å¹³ä»£ç "è®¸å¯è¯ï¼Œæ—¢ä¿æŒå¼€æºç‰¹æ€§ï¼Œåˆä¸ºå•†ä¸šä½¿ç”¨æä¾›äº†å¯æŒç»­çš„å•†ä¸šæ¨¡å¼ã€‚

#### æ ¸å¿ƒä»·å€¼ä¸»å¼ 

- **æ— ä»£ç /ä½ä»£ç è‡ªåŠ¨åŒ–**: é€šè¿‡å¯è§†åŒ–ç•Œé¢æ„å»ºå¤æ‚çš„ä¸šåŠ¡æµç¨‹ï¼Œå¤§å¤§é™ä½äº†è‡ªåŠ¨åŒ–çš„æŠ€æœ¯é—¨æ§›
- **éšç§ä¼˜å…ˆ**: æ”¯æŒå®Œå…¨æœ¬åœ°éƒ¨ç½²ï¼Œæ‰€æœ‰æ•°æ®å¤„ç†éƒ½åœ¨æ‚¨çš„æ§åˆ¶èŒƒå›´å†…
- **é«˜åº¦å¯æ‰©å±•**: æä¾›äº†400+ä¸ªé¢„æ„å»ºçš„é›†æˆèŠ‚ç‚¹ï¼ŒåŒæ—¶æ”¯æŒè‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘
- **AIèƒ½åŠ›é›†æˆ**: åŸç”Ÿæ”¯æŒå„ç§AIæœåŠ¡ï¼Œè®©å·¥ä½œæµå…·å¤‡æ™ºèƒ½å¤„ç†èƒ½åŠ›

### n8nçš„æŠ€æœ¯æ¶æ„

n8né‡‡ç”¨ç°ä»£åŒ–çš„æŠ€æœ¯æ ˆå’Œæ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œç¡®ä¿äº†å¹³å°çš„å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

#### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç”¨æˆ·å±‚"
        UI[Webç¼–è¾‘å™¨]
        CLI[å‘½ä»¤è¡Œå·¥å…·]
        API[REST API]
    end
    
    subgraph "åº”ç”¨å±‚"
        WE[å·¥ä½œæµå¼•æ“]
        NM[èŠ‚ç‚¹ç®¡ç†å™¨]
        EM[æ‰§è¡Œç®¡ç†å™¨]
        AM[è®¤è¯ç®¡ç†å™¨]
    end
    
    subgraph "æ ¸å¿ƒå±‚"
        CR[æ ¸å¿ƒè¿è¡Œæ—¶]
        WP[å·¥ä½œæµå¤„ç†å™¨]
        NE[èŠ‚ç‚¹æ‰§è¡Œå™¨]
        DM[æ•°æ®æ˜ å°„å™¨]
    end
    
    subgraph "æ•°æ®å±‚"
        DB[(æ•°æ®åº“)]
        FS[æ–‡ä»¶ç³»ç»Ÿ]
        QU[é˜Ÿåˆ—ç³»ç»Ÿ]
        CH[ç¼“å­˜ç³»ç»Ÿ]
    end
    
    subgraph "é›†æˆå±‚"
        N1[HTTPèŠ‚ç‚¹]
        N2[æ•°æ®åº“èŠ‚ç‚¹]
        N3[AIèŠ‚ç‚¹]
        N4[è‡ªå®šä¹‰èŠ‚ç‚¹]
    end
    
    UI --> WE
    CLI --> WE
    API --> WE
    WE --> CR
    NM --> NE
    EM --> QU
    CR --> DB
    NE --> N1
    NE --> N2
    NE --> N3
    NE --> N4
```

#### å…³é”®ç»„ä»¶è¯¦è§£

**1. å·¥ä½œæµå¼•æ“ (Workflow Engine)**
- è´Ÿè´£è§£æå·¥ä½œæµå®šä¹‰å’Œæ‰§è¡Œè®¡åˆ’
- ç®¡ç†èŠ‚ç‚¹ä¹‹é—´çš„æ•°æ®æµè½¬
- å¤„ç†æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯é€»è¾‘
- æ”¯æŒå¹¶è¡Œå’Œä¸²è¡Œæ‰§è¡Œæ¨¡å¼

**2. èŠ‚ç‚¹æ‰§è¡Œå™¨ (Node Executor)**
- åŠ¨æ€åŠ è½½å’Œæ‰§è¡ŒèŠ‚ç‚¹ä»£ç 
- ç®¡ç†èŠ‚ç‚¹çš„ç”Ÿå‘½å‘¨æœŸ
- å¤„ç†èŠ‚ç‚¹é—´çš„æ•°æ®ä¼ é€’
- æä¾›é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

**3. æ•°æ®æ˜ å°„å™¨ (Data Mapper)**
- å¤„ç†å¤æ‚çš„æ•°æ®è½¬æ¢å’Œæ˜ å°„
- æ”¯æŒè¡¨è¾¾å¼è¯­è¨€è¿›è¡ŒåŠ¨æ€è®¡ç®—
- æä¾›æ•°æ®éªŒè¯å’Œç±»å‹è½¬æ¢
- ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½

### n8nçš„æ ¸å¿ƒæ¦‚å¿µ

#### 1. å·¥ä½œæµ (Workflows)

å·¥ä½œæµæ˜¯n8nä¸­çš„åŸºæœ¬æ‰§è¡Œå•å…ƒï¼Œç”±å¤šä¸ªç›¸äº’è¿æ¥çš„èŠ‚ç‚¹ç»„æˆã€‚æ¯ä¸ªå·¥ä½œæµéƒ½æœ‰æ˜ç¡®çš„è¾“å…¥ã€å¤„ç†å’Œè¾“å‡ºå®šä¹‰ã€‚

```typescript
// å·¥ä½œæµå®šä¹‰ç»“æ„
interface WorkflowDefinition {
  id: string;                    // å·¥ä½œæµå”¯ä¸€æ ‡è¯†
  name: string;                  // å·¥ä½œæµåç§°
  nodes: INode[];               // èŠ‚ç‚¹åˆ—è¡¨
  connections: IConnections;     // èŠ‚ç‚¹è¿æ¥å…³ç³»
  active: boolean;              // æ˜¯å¦æ¿€æ´»
  settings: IWorkflowSettings;   // å·¥ä½œæµè®¾ç½®
  staticData?: IDataObject;      // é™æ€æ•°æ®
  pinData?: IPinData;           // å›ºå®šæ•°æ®
}

// èŠ‚ç‚¹å®šä¹‰ç»“æ„
interface INode {
  id: string;                   // èŠ‚ç‚¹ID
  name: string;                 // èŠ‚ç‚¹åç§°
  type: string;                 // èŠ‚ç‚¹ç±»å‹
  typeVersion: number;          // èŠ‚ç‚¹ç‰ˆæœ¬
  position: [number, number];   // èŠ‚ç‚¹ä½ç½®
  parameters: INodeParameters;  // èŠ‚ç‚¹å‚æ•°
  credentials?: INodeCredentials; // è®¤è¯ä¿¡æ¯
  webhookId?: string;           // Webhook ID
  onError?: WorkflowExecuteMode; // é”™è¯¯å¤„ç†æ¨¡å¼
}
```

#### 2. èŠ‚ç‚¹ (Nodes)

èŠ‚ç‚¹æ˜¯å·¥ä½œæµçš„åŸºæœ¬ç»„æˆå•å…ƒï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ç‰¹å®šçš„åŠŸèƒ½å’Œç”¨é€”ã€‚

**èŠ‚ç‚¹åˆ†ç±»**:

- **è§¦å‘èŠ‚ç‚¹ (Trigger Nodes)**: å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ
  - WebhookèŠ‚ç‚¹ï¼šæ¥æ”¶HTTPè¯·æ±‚
  - CronèŠ‚ç‚¹ï¼šå®šæ—¶æ‰§è¡Œ
  - æ–‡ä»¶ç›‘è§†å™¨ï¼šç›‘æ§æ–‡ä»¶å˜åŒ–
  - é‚®ä»¶è§¦å‘å™¨ï¼šç›‘å¬æ–°é‚®ä»¶

- **å¸¸è§„èŠ‚ç‚¹ (Regular Nodes)**: æ‰§è¡Œå…·ä½“æ“ä½œ
  - HTTPè¯·æ±‚èŠ‚ç‚¹ï¼šå‘é€APIè¯·æ±‚
  - æ•°æ®åº“èŠ‚ç‚¹ï¼šæ•°æ®åº“æ“ä½œ
  - é‚®ä»¶èŠ‚ç‚¹ï¼šå‘é€é‚®ä»¶
  - æ–‡ä»¶æ“ä½œèŠ‚ç‚¹ï¼šå¤„ç†æ–‡ä»¶

- **æ§åˆ¶èŠ‚ç‚¹ (Control Nodes)**: æ§åˆ¶æ‰§è¡Œæµç¨‹
  - IFèŠ‚ç‚¹ï¼šæ¡ä»¶åˆ¤æ–­
  - SwitchèŠ‚ç‚¹ï¼šå¤šè·¯åˆ†æ”¯
  - MergeèŠ‚ç‚¹ï¼šæ•°æ®åˆå¹¶
  - WaitèŠ‚ç‚¹ï¼šç­‰å¾…å»¶è¿Ÿ

#### 3. æ•°æ®æµè½¬ (Data Flow)

n8nä¸­çš„æ•°æ®ä»¥JSONæ ¼å¼åœ¨èŠ‚ç‚¹é—´æµè½¬ï¼Œæ¯ä¸ªæ•°æ®é¡¹éƒ½åŒ…å«ä¸»è¦æ•°æ®å’Œå¯é€‰çš„äºŒè¿›åˆ¶æ•°æ®ã€‚

```typescript
// æ•°æ®é¡¹ç»“æ„
interface INodeExecutionData {
  json: IDataObject;           // ä¸»è¦JSONæ•°æ®
  binary?: IBinaryKeyData;     // äºŒè¿›åˆ¶æ•°æ®ï¼ˆå¯é€‰ï¼‰
  pairedItem?: IPairedItemData; // é…å¯¹é¡¹æ•°æ®
  error?: NodeApiError;        // é”™è¯¯ä¿¡æ¯
}

// ç¤ºä¾‹æ•°æ®æµ
const executionData: INodeExecutionData[] = [
  {
    json: {
      id: 1,
      name: "å¼ ä¸‰",
      email: "zhangsan@example.com",
      department: "æŠ€æœ¯éƒ¨"
    },
    binary: {
      avatar: {
        data: "base64_encoded_image_data",
        mimeType: "image/jpeg",
        fileName: "avatar.jpg"
      }
    }
  },
  {
    json: {
      id: 2,
      name: "æå››",
      email: "lisi@example.com",
      department: "é”€å”®éƒ¨"
    }
  }
];
```

#### 4. è¡¨è¾¾å¼è¯­è¨€ (Expression Language)

n8næä¾›äº†å¼ºå¤§çš„è¡¨è¾¾å¼è¯­è¨€ï¼Œå…è®¸åœ¨å·¥ä½œæµä¸­è¿›è¡ŒåŠ¨æ€æ•°æ®å¤„ç†å’Œè®¡ç®—ã€‚

**åŸºç¡€è¯­æ³•**:
```javascript
// è®¿é—®è¾“å…¥æ•°æ®
{{ $json.fieldName }}              // è®¿é—®å½“å‰èŠ‚ç‚¹çš„JSONå­—æ®µ
{{ $binary.dataKey }}              // è®¿é—®äºŒè¿›åˆ¶æ•°æ®
{{ $input.all() }}                 // è·å–æ‰€æœ‰è¾“å…¥æ•°æ®
{{ $input.first() }}               // è·å–ç¬¬ä¸€ä¸ªè¾“å…¥é¡¹

// è®¿é—®å…¶ä»–èŠ‚ç‚¹æ•°æ®
{{ $node["èŠ‚ç‚¹åç§°"].json.field }}   // è®¿é—®æŒ‡å®šèŠ‚ç‚¹çš„æ•°æ®
{{ $("èŠ‚ç‚¹åç§°").all() }}            // è·å–æŒ‡å®šèŠ‚ç‚¹çš„æ‰€æœ‰æ•°æ®

// å·¥ä½œæµå’Œæ‰§è¡Œä¿¡æ¯
{{ $workflow.id }}                  // å·¥ä½œæµID
{{ $workflow.name }}                // å·¥ä½œæµåç§°
{{ $execution.id }}                 // æ‰§è¡ŒID
{{ $execution.mode }}               // æ‰§è¡Œæ¨¡å¼

// ç¯å¢ƒå’Œç³»ç»Ÿä¿¡æ¯
{{ $env.NODE_ENV }}                 // ç¯å¢ƒå˜é‡
{{ $now }}                          // å½“å‰æ—¶é—´æˆ³
{{ $today }}                        // ä»Šå¤©çš„æ—¥æœŸ
{{ $vars.customVariable }}          // è‡ªå®šä¹‰å˜é‡
```

**é«˜çº§è¡¨è¾¾å¼ç¤ºä¾‹**:
```javascript
// æ¡ä»¶è¡¨è¾¾å¼
{{ $json.score >= 80 ? 'ä¼˜ç§€' : $json.score >= 60 ? 'åŠæ ¼' : 'ä¸åŠæ ¼' }}

// æ•°ç»„æ“ä½œ
{{ $json.items.filter(item => item.price > 100) }}
{{ $json.users.map(user => user.email) }}

// å­—ç¬¦ä¸²å¤„ç†
{{ $json.name.toUpperCase() }}
{{ $json.content.replace(/\s+/g, ' ').trim() }}

// æ—¥æœŸè®¡ç®—
{{ new Date($json.created_at).toISOString().split('T')[0] }}
{{ DateTime.now().minus({ days: 7 }).toFormat('yyyy-MM-dd') }}

// æ•°å­¦è®¡ç®—
{{ Math.round($json.price * 1.2 * 100) / 100 }}
{{ $json.items.reduce((sum, item) => sum + item.quantity, 0) }}
```

### n8nçš„éƒ¨ç½²æ¶æ„é€‰æ‹©

#### 1. å•æœºéƒ¨ç½²

é€‚ç”¨äºå°å›¢é˜Ÿå’Œå¼€å‘æµ‹è¯•ç¯å¢ƒã€‚

**Docker Composeé…ç½®**:
```yaml
version: '3.8'

services:
  n8n:
    image: n8nio/n8n
    restart: always
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=password
      - N8N_HOST=${SUBDOMAIN}.${DOMAIN_NAME}
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://${SUBDOMAIN}.${DOMAIN_NAME}/
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}
    volumes:
      - ~/.n8n:/home/node/.n8n
      - ./workflows:/home/node/workflows
      - ./custom-nodes:/home/node/custom-nodes
```

#### 2. åˆ†å¸ƒå¼éƒ¨ç½²

é€‚ç”¨äºå¤§è§„æ¨¡ä¼ä¸šç¯å¢ƒï¼Œæ”¯æŒé«˜å¯ç”¨å’Œè´Ÿè½½å‡è¡¡ã€‚

**ä¸»ä»æ¶æ„**:
```yaml
version: '3.8'

services:
  # ä¸»èŠ‚ç‚¹ - è´Ÿè´£UIå’Œå·¥ä½œæµç®¡ç†
  n8n-main:
    image: n8nio/n8n
    restart: always
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n
      - EXECUTIONS_MODE=queue
      - QUEUE_BULL_REDIS_HOST=redis
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    depends_on:
      - postgres
      - redis

  # å·¥ä½œèŠ‚ç‚¹ - è´Ÿè´£æ‰§è¡Œå·¥ä½œæµ
  n8n-worker:
    image: n8nio/n8n
    restart: always
    command: n8n worker
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n
      - QUEUE_BULL_REDIS_HOST=redis
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    depends_on:
      - postgres
      - redis
    deploy:
      replicas: 3

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:13
    restart: always
    environment:
      - POSTGRES_DB=n8n
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=n8n
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redisé˜Ÿåˆ—ç³»ç»Ÿ
  redis:
    image: redis:6-alpine
    restart: always
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

### n8nçš„å®‰å…¨æœºåˆ¶

#### 1. è®¤è¯å’Œæˆæƒ

**åŸºç¡€è®¤è¯é…ç½®**:
```bash
# ç¯å¢ƒå˜é‡é…ç½®
export N8N_BASIC_AUTH_ACTIVE=true
export N8N_BASIC_AUTH_USER=admin
export N8N_BASIC_AUTH_PASSWORD=secure_password

# LDAPé›†æˆ
export N8N_USER_MANAGEMENT_LDAP_ENABLED=true
export N8N_USER_MANAGEMENT_LDAP_SERVER_URL=ldap://ldap.company.com
export N8N_USER_MANAGEMENT_LDAP_BIND_DN=cn=admin,dc=company,dc=com
export N8N_USER_MANAGEMENT_LDAP_BIND_PASSWORD=ldap_password

# JWTé…ç½®
export N8N_USER_MANAGEMENT_JWT_SECRET=your_jwt_secret_key
export N8N_USER_MANAGEMENT_JWT_DURATION=7d
```

#### 2. æ•°æ®åŠ å¯†

**æ•æ„Ÿæ•°æ®åŠ å¯†**:
```typescript
// è‡ªå®šä¹‰åŠ å¯†å®ç°
import { createCipher, createDecipher } from 'crypto';

class DataEncryption {
  private encryptionKey: string;

  constructor(key: string) {
    this.encryptionKey = key;
  }

  encrypt(data: string): string {
    const cipher = createCipher('aes-256-cbc', this.encryptionKey);
    let encrypted = cipher.update(data, 'utf8', 'hex');
    encrypted += cipher.final('hex');
    return encrypted;
  }

  decrypt(encryptedData: string): string {
    const decipher = createDecipher('aes-256-cbc', this.encryptionKey);
    let decrypted = decipher.update(encryptedData, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    return decrypted;
  }
}

// åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨åŠ å¯†
export class SecureDataProcessor implements INodeType {
  private encryption = new DataEncryption(process.env.N8N_ENCRYPTION_KEY!);

  async execute(this: IExecuteFunctions): Promise<INodeExecutionData[][]> {
    const items = this.getInputData();
    
    const processedItems = items.map(item => {
      const sensitiveData = item.json.sensitiveField as string;
      const encryptedData = this.encryption.encrypt(sensitiveData);
      
      return {
        json: {
          ...item.json,
          sensitiveField: encryptedData,
          _encrypted: true
        }
      };
    });

    return [processedItems];
  }
}
```

#### 3. ç½‘ç»œå®‰å…¨

**HTTPSå’ŒSSLé…ç½®**:
```nginx
# Nginxé…ç½®ç¤ºä¾‹
server {
    listen 443 ssl http2;
    server_name n8n.yourdomain.com;

    ssl_certificate /path/to/certificate.crt;
    ssl_certificate_key /path/to/private.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256;

    # å®‰å…¨å¤´é…ç½®
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload";
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";

    location / {
        proxy_pass http://127.0.0.1:5678;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}
```

## è‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘è¯¦è§£

å½“n8nå†…ç½®çš„400+èŠ‚ç‚¹æ— æ³•æ»¡è¶³ç‰¹å®šä¸šåŠ¡éœ€æ±‚æ—¶ï¼Œå¼€å‘è‡ªå®šä¹‰èŠ‚ç‚¹æ˜¯æ‰©å±•å¹³å°åŠŸèƒ½çš„æœ€ä½³æ–¹å¼ã€‚æœ¬èŠ‚å°†è¯¦ç»†ä»‹ç»èŠ‚ç‚¹å¼€å‘çš„å„ä¸ªæ–¹é¢ã€‚

### å¼€å‘ç¯å¢ƒå‡†å¤‡

#### 1. é¡¹ç›®åˆå§‹åŒ–

ä½¿ç”¨å®˜æ–¹æä¾›çš„èŠ‚ç‚¹å¼€å‘æ¨¡æ¿æ¥ç¡®ä¿æœ€ä½³å®è·µï¼š

```bash
# ä»æ¨¡æ¿åˆ›å»ºæ–°é¡¹ç›®
git clone https://github.com/n8n-io/n8n-nodes-starter.git my-custom-node
cd my-custom-node

# å®‰è£…ä¾èµ–
npm install

# æ¸…ç†ç¤ºä¾‹æ–‡ä»¶
rm -rf nodes/ExampleNode nodes/HTTPBin
rm -rf credentials/ExampleCredentials.credentials.ts credentials/HttpBinApi.credentials.ts

# åˆ›å»ºæ–°çš„èŠ‚ç‚¹ç›®å½•ç»“æ„
mkdir -p nodes/WeatherService
mkdir -p credentials
```

#### 2. å¼€å‘å·¥å…·é…ç½®

**TypeScripté…ç½®** (`tsconfig.json`):
```json
{
  "compilerOptions": {
    "target": "es2019",
    "module": "commonjs",
    "lib": ["es2019"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "noImplicitAny": false,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true
  },
  "include": [
    "credentials/**/*",
    "nodes/**/*"
  ],
  "exclude": [
    "node_modules/**/*",
    "dist/**/*"
  ]
}
```

**ESLinté…ç½®** (`.eslintrc.js`):
```javascript
module.exports = {
  root: true,
  env: {
    es6: true,
    node: true
  },
  parser: '@typescript-eslint/parser',
  parserOptions: {
    project: './tsconfig.json',
    sourceType: 'module',
    ecmaVersion: 2019
  },
  plugins: ['@typescript-eslint'],
  extends: [
    'eslint:recommended',
    '@typescript-eslint/recommended'
  ],
  rules: {
    '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
    '@typescript-eslint/explicit-function-return-type': 'off',
    '@typescript-eslint/no-explicit-any': 'off',
    '@typescript-eslint/no-non-null-assertion': 'off'
  }
};
```

### èŠ‚ç‚¹ç±»å‹è¯¦è§£

#### 1. å£°æ˜å¼èŠ‚ç‚¹ (Declarative Nodes)

å£°æ˜å¼èŠ‚ç‚¹é€šè¿‡JSONé…ç½®æ¥å®šä¹‰è¡Œä¸ºï¼Œé€‚åˆç®€å•çš„APIé›†æˆåœºæ™¯ã€‚

**èŠ‚ç‚¹å…ƒæ•°æ®æ–‡ä»¶** (`nodes/WeatherService/WeatherService.node.json`):
```json
{
  "displayName": "Weather Service",
  "name": "weatherService",
  "icon": "fa:cloud-sun",
  "group": ["input"],
  "version": 1,
  "description": "è·å–å¤©æ°”ä¿¡æ¯çš„ä¸“ä¸šæœåŠ¡èŠ‚ç‚¹",
  "defaults": {
    "name": "Weather Service"
  },
  "inputs": ["main"],
  "outputs": ["main"],
  "credentials": [
    {
      "name": "weatherServiceApi",
      "required": true
    }
  ],
  "requestDefaults": {
    "baseURL": "https://api.weatherservice.com/v1",
    "headers": {
      "Accept": "application/json",
      "Content-Type": "application/json"
    }
  },
  "properties": [
    {
      "displayName": "Resource",
      "name": "resource",
      "type": "options",
      "noDataExpression": true,
      "options": [
        {
          "name": "Current Weather",
          "value": "currentWeather"
        },
        {
          "name": "Weather Forecast",
          "value": "forecast"
        },
        {
          "name": "Historical Weather",
          "value": "historical"
        }
      ],
      "default": "currentWeather"
    },
    {
      "displayName": "Operation",
      "name": "operation",
      "type": "options",
      "noDataExpression": true,
      "displayOptions": {
        "show": {
          "resource": ["currentWeather"]
        }
      },
      "options": [
        {
          "name": "Get Current Weather",
          "value": "getCurrent",
          "action": "Get current weather for a location",
          "routing": {
            "request": {
              "method": "GET",
              "url": "/current"
            },
            "output": {
              "postReceive": [
                {
                  "type": "rootProperty",
                  "properties": {
                    "property": "data"
                  }
                }
              ]
            }
          }
        }
      ],
      "default": "getCurrent"
    },
    {
      "displayName": "Location",
      "name": "location",
      "type": "string",
      "default": "",
      "placeholder": "Beijing, China",
      "description": "åŸå¸‚åç§°æˆ–åæ ‡",
      "required": true,
      "routing": {
        "request": {
          "qs": {
            "q": "={{ $value }}"
          }
        }
      }
    },
    {
      "displayName": "Units",
      "name": "units",
      "type": "options",
      "options": [
        {
          "name": "Metric (Â°C, m/s)",
          "value": "metric"
        },
        {
          "name": "Imperial (Â°F, mph)",
          "value": "imperial"
        },
        {
          "name": "Kelvin (K)",
          "value": "standard"
        }
      ],
      "default": "metric",
      "routing": {
        "request": {
          "qs": {
            "units": "={{ $value }}"
          }
        }
      }
    },
    {
      "displayName": "Additional Options",
      "name": "additionalOptions",
      "type": "collection",
      "placeholder": "Add Option",
      "default": {},
      "options": [
        {
          "displayName": "Include Air Quality",
          "name": "includeAirQuality",
          "type": "boolean",
          "default": false,
          "routing": {
            "request": {
              "qs": {
                "include_air_quality": "={{ $value }}"
              }
            }
          }
        },
        {
          "displayName": "Language",
          "name": "language",
          "type": "options",
          "options": [
            { "name": "English", "value": "en" },
            { "name": "ä¸­æ–‡", "value": "zh" },
            { "name": "EspaÃ±ol", "value": "es" },
            { "name": "FranÃ§ais", "value": "fr" }
          ],
          "default": "en",
          "routing": {
            "request": {
              "qs": {
                "lang": "={{ $value }}"
              }
            }
          }
        }
      ]
    }
  ]
}
```

#### 2. ç¨‹åºå¼èŠ‚ç‚¹ (Programmatic Nodes)

ç¨‹åºå¼èŠ‚ç‚¹æä¾›å®Œå…¨çš„ç¼–ç¨‹æ§åˆ¶ï¼Œé€‚åˆå¤æ‚çš„ä¸šåŠ¡é€»è¾‘ã€‚

**èŠ‚ç‚¹å®ç°æ–‡ä»¶** (`nodes/DataProcessor/DataProcessor.node.ts`):
```typescript
import {
  IExecuteFunctions,
  INodeExecutionData,
  INodeType,
  INodeTypeDescription,
  NodeOperationError,
  NodeConnectionType,
} from 'n8n-workflow';

export class DataProcessor implements INodeType {
  description: INodeTypeDescription = {
    displayName: 'é«˜çº§æ•°æ®å¤„ç†å™¨',
    name: 'dataProcessor',
    icon: 'fa:cogs',
    group: ['transform'],
    version: 1,
    description: 'æä¾›é«˜çº§æ•°æ®å¤„ç†å’Œè½¬æ¢åŠŸèƒ½',
    defaults: {
      name: 'é«˜çº§æ•°æ®å¤„ç†å™¨',
    },
    inputs: [NodeConnectionType.Main],
    outputs: [NodeConnectionType.Main],
    properties: [
      {
        displayName: 'å¤„ç†æ“ä½œ',
        name: 'operation',
        type: 'options',
        noDataExpression: true,
        options: [
          {
            name: 'æ•°æ®æ¸…æ´—',
            value: 'cleanData',
            description: 'æ¸…ç†å’Œæ ‡å‡†åŒ–æ•°æ®',
            action: 'æ‰§è¡Œæ•°æ®æ¸…æ´—æ“ä½œ',
          },
          {
            name: 'æ•°æ®èšåˆ',
            value: 'aggregateData',
            description: 'èšåˆå’Œåˆ†ç»„æ•°æ®',
            action: 'æ‰§è¡Œæ•°æ®èšåˆæ“ä½œ',
          },
          {
            name: 'æ•°æ®éªŒè¯',
            value: 'validateData',
            description: 'éªŒè¯æ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§',
            action: 'æ‰§è¡Œæ•°æ®éªŒè¯æ“ä½œ',
          },
          {
            name: 'æ•°æ®è½¬æ¢',
            value: 'transformData',
            description: 'è½¬æ¢æ•°æ®æ ¼å¼å’Œç»“æ„',
            action: 'æ‰§è¡Œæ•°æ®è½¬æ¢æ“ä½œ',
          },
        ],
        default: 'cleanData',
      },
      {
        displayName: 'å¤„ç†é…ç½®',
        name: 'processingConfig',
        type: 'collection',
        placeholder: 'æ·»åŠ é…ç½®',
        default: {},
        options: [
          {
            displayName: 'ç§»é™¤ç©ºå€¼',
            name: 'removeNull',
            type: 'boolean',
            default: true,
            description: 'æ˜¯å¦ç§»é™¤nullã€undefinedå’Œç©ºå­—ç¬¦ä¸²',
          },
          {
            displayName: 'å¤§å°å†™è½¬æ¢',
            name: 'caseTransform',
            type: 'options',
            options: [
              { name: 'ä¿æŒåŸæ ·', value: 'none' },
              { name: 'è½¬ä¸ºå°å†™', value: 'lower' },
              { name: 'è½¬ä¸ºå¤§å†™', value: 'upper' },
              { name: 'é¦–å­—æ¯å¤§å†™', value: 'title' },
              { name: 'é©¼å³°å‘½å', value: 'camel' },
            ],
            default: 'none',
          },
          {
            displayName: 'æ•°æ®ç±»å‹è½¬æ¢',
            name: 'typeConversion',
            type: 'boolean',
            default: false,
            description: 'è‡ªåŠ¨è½¬æ¢æ•°æ®ç±»å‹ï¼ˆæ•°å­—ã€å¸ƒå°”å€¼ã€æ—¥æœŸï¼‰',
          },
          {
            displayName: 'å­—æ®µæ˜ å°„',
            name: 'fieldMapping',
            type: 'fixedCollection',
            default: { mappings: [] },
            typeOptions: {
              multipleValues: true,
            },
            options: [
              {
                displayName: 'æ˜ å°„è§„åˆ™',
                name: 'mappings',
                values: [
                  {
                    displayName: 'æºå­—æ®µ',
                    name: 'source',
                    type: 'string',
                    default: '',
                    placeholder: 'original_field_name',
                  },
                  {
                    displayName: 'ç›®æ ‡å­—æ®µ',
                    name: 'target',
                    type: 'string',
                    default: '',
                    placeholder: 'new_field_name',
                  },
                  {
                    displayName: 'è½¬æ¢å‡½æ•°',
                    name: 'transform',
                    type: 'string',
                    default: '',
                    placeholder: 'value => value.toString()',
                    description: 'å¯é€‰çš„JavaScriptè½¬æ¢å‡½æ•°',
                  },
                ],
              },
            ],
          },
        ],
      },
      {
        displayName: 'éªŒè¯è§„åˆ™',
        name: 'validationRules',
        type: 'fixedCollection',
        displayOptions: {
          show: {
            operation: ['validateData'],
          },
        },
        default: { rules: [] },
        typeOptions: {
          multipleValues: true,
        },
        options: [
          {
            displayName: 'éªŒè¯è§„åˆ™',
            name: 'rules',
            values: [
              {
                displayName: 'å­—æ®µå',
                name: 'fieldName',
                type: 'string',
                default: '',
                required: true,
              },
              {
                displayName: 'è§„åˆ™ç±»å‹',
                name: 'ruleType',
                type: 'options',
                options: [
                  { name: 'å¿…å¡«', value: 'required' },
                  { name: 'é‚®ç®±æ ¼å¼', value: 'email' },
                  { name: 'æ•°å­—èŒƒå›´', value: 'numberRange' },
                  { name: 'å­—ç¬¦ä¸²é•¿åº¦', value: 'stringLength' },
                  { name: 'æ­£åˆ™è¡¨è¾¾å¼', value: 'regex' },
                ],
                default: 'required',
              },
              {
                displayName: 'è§„åˆ™å‚æ•°',
                name: 'ruleParams',
                type: 'string',
                default: '',
                placeholder: '{"min": 0, "max": 100}',
                description: 'è§„åˆ™å‚æ•°ï¼ˆJSONæ ¼å¼ï¼‰',
              },
            ],
          },
        ],
      },
    ],
  };

  async execute(this: IExecuteFunctions): Promise<INodeExecutionData[][]> {
    const items = this.getInputData();
    const operation = this.getNodeParameter('operation', 0) as string;
    const processingConfig = this.getNodeParameter('processingConfig', 0) as any;

    const returnData: INodeExecutionData[] = [];

    for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
      try {
        const item = items[itemIndex];
        let processedData: any;

        switch (operation) {
          case 'cleanData':
            processedData = await this.cleanData(item.json, processingConfig);
            break;

          case 'aggregateData':
            processedData = await this.aggregateData(items.map(i => i.json), processingConfig);
            // å¯¹äºèšåˆæ“ä½œï¼Œåªè¿”å›ä¸€æ¬¡ç»“æœ
            if (itemIndex === 0) {
              returnData.push({ json: processedData });
            }
            continue;

          case 'validateData':
            const validationRules = this.getNodeParameter('validationRules', itemIndex) as any;
            processedData = await this.validateData(item.json, validationRules);
            break;

          case 'transformData':
            processedData = await this.transformData(item.json, processingConfig);
            break;

          default:
            throw new NodeOperationError(this.getNode(), `æœªçŸ¥æ“ä½œç±»å‹: ${operation}`, {
              itemIndex,
            });
        }

        returnData.push({
          json: processedData,
          binary: item.binary,
          pairedItem: { item: itemIndex },
        });

      } catch (error) {
        if (this.continueOnFail()) {
          returnData.push({
            json: {
              error: error.message,
              itemIndex,
              originalData: items[itemIndex].json,
            },
            pairedItem: { item: itemIndex },
          });
          continue;
        }
        throw error;
      }
    }

    return [returnData];
  }

  // æ•°æ®æ¸…æ´—æ–¹æ³•
  private async cleanData(data: any, config: any): Promise<any> {
    let cleaned = { ...data };

    // ç§»é™¤ç©ºå€¼
    if (config.removeNull) {
      cleaned = this.removeNullValues(cleaned);
    }

    // å¤§å°å†™è½¬æ¢
    if (config.caseTransform && config.caseTransform !== 'none') {
      cleaned = this.transformCase(cleaned, config.caseTransform);
    }

    // æ•°æ®ç±»å‹è½¬æ¢
    if (config.typeConversion) {
      cleaned = this.convertTypes(cleaned);
    }

    // å­—æ®µæ˜ å°„
    if (config.fieldMapping && config.fieldMapping.mappings) {
      cleaned = await this.applyFieldMapping(cleaned, config.fieldMapping.mappings);
    }

    return cleaned;
  }

  // æ•°æ®èšåˆæ–¹æ³•
  private async aggregateData(dataArray: any[], config: any): Promise<any> {
    const result = {
      totalCount: dataArray.length,
      summary: {},
      groups: {},
      statistics: {},
    };

    // åŸºç¡€ç»Ÿè®¡
    if (dataArray.length > 0) {
      const sampleData = dataArray[0];
      Object.keys(sampleData).forEach(key => {
        if (typeof sampleData[key] === 'number') {
          const values = dataArray.map(item => item[key]).filter(v => typeof v === 'number');
          result.statistics[key] = {
            count: values.length,
            sum: values.reduce((a, b) => a + b, 0),
            avg: values.reduce((a, b) => a + b, 0) / values.length,
            min: Math.min(...values),
            max: Math.max(...values),
          };
        } else if (typeof sampleData[key] === 'string') {
          const values = dataArray.map(item => item[key]).filter(v => typeof v === 'string');
          const counts = {};
          values.forEach(v => counts[v] = (counts[v] || 0) + 1);
          result.summary[key] = counts;
        }
      });
    }

    return result;
  }

  // æ•°æ®éªŒè¯æ–¹æ³•
  private async validateData(data: any, validationConfig: any): Promise<any> {
    const validationResult = {
      ...data,
      _validation: {
        isValid: true,
        errors: [],
        warnings: [],
        validatedAt: new Date().toISOString(),
      },
    };

    if (validationConfig.rules) {
      for (const rule of validationConfig.rules) {
        const fieldValue = data[rule.fieldName];
        const ruleParams = rule.ruleParams ? JSON.parse(rule.ruleParams) : {};

        let isValid = true;
        let errorMessage = '';

        switch (rule.ruleType) {
          case 'required':
            isValid = fieldValue !== null && fieldValue !== undefined && fieldValue !== '';
            errorMessage = `å­—æ®µ ${rule.fieldName} æ˜¯å¿…å¡«é¡¹`;
            break;

          case 'email':
            const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
            isValid = !fieldValue || emailRegex.test(fieldValue);
            errorMessage = `å­—æ®µ ${rule.fieldName} ä¸æ˜¯æœ‰æ•ˆçš„é‚®ç®±æ ¼å¼`;
            break;

          case 'numberRange':
            const numValue = Number(fieldValue);
            isValid = !isNaN(numValue) && 
                     (!ruleParams.min || numValue >= ruleParams.min) &&
                     (!ruleParams.max || numValue <= ruleParams.max);
            errorMessage = `å­—æ®µ ${rule.fieldName} åº”åœ¨ ${ruleParams.min || 'æ— é™'} åˆ° ${ruleParams.max || 'æ— é™'} ä¹‹é—´`;
            break;

          case 'stringLength':
            const strValue = String(fieldValue || '');
            isValid = (!ruleParams.min || strValue.length >= ruleParams.min) &&
                     (!ruleParams.max || strValue.length <= ruleParams.max);
            errorMessage = `å­—æ®µ ${rule.fieldName} é•¿åº¦åº”åœ¨ ${ruleParams.min || 0} åˆ° ${ruleParams.max || 'æ— é™'} ä¹‹é—´`;
            break;

          case 'regex':
            const regex = new RegExp(ruleParams.pattern, ruleParams.flags || '');
            isValid = !fieldValue || regex.test(fieldValue);
            errorMessage = `å­—æ®µ ${rule.fieldName} ä¸åŒ¹é…æŒ‡å®šçš„æ­£åˆ™è¡¨è¾¾å¼`;
            break;
        }

        if (!isValid) {
          validationResult._validation.isValid = false;
          validationResult._validation.errors.push({
            field: rule.fieldName,
            rule: rule.ruleType,
            message: errorMessage,
            value: fieldValue,
          });
        }
      }
    }

    return validationResult;
  }

  // æ•°æ®è½¬æ¢æ–¹æ³•
  private async transformData(data: any, config: any): Promise<any> {
    let transformed = { ...data };

    // åº”ç”¨å­—æ®µæ˜ å°„
    if (config.fieldMapping && config.fieldMapping.mappings) {
      transformed = await this.applyFieldMapping(transformed, config.fieldMapping.mappings);
    }

    return transformed;
  }

  // è¾…åŠ©æ–¹æ³•ï¼šç§»é™¤ç©ºå€¼
  private removeNullValues(obj: any): any {
    const result = {};
    Object.keys(obj).forEach(key => {
      const value = obj[key];
      if (value !== null && value !== undefined && value !== '') {
        if (typeof value === 'object' && !Array.isArray(value)) {
          const cleaned = this.removeNullValues(value);
          if (Object.keys(cleaned).length > 0) {
            result[key] = cleaned;
          }
        } else {
          result[key] = value;
        }
      }
    });
    return result;
  }

  // è¾…åŠ©æ–¹æ³•ï¼šå¤§å°å†™è½¬æ¢
  private transformCase(obj: any, caseType: string): any {
    const result = {};
    Object.keys(obj).forEach(key => {
      let value = obj[key];
      if (typeof value === 'string') {
        switch (caseType) {
          case 'lower':
            value = value.toLowerCase();
            break;
          case 'upper':
            value = value.toUpperCase();
            break;
          case 'title':
            value = value.replace(/\w\S*/g, txt => 
              txt.charAt(0).toUpperCase() + txt.substr(1).toLowerCase()
            );
            break;
          case 'camel':
            value = value.replace(/(?:^\w|[A-Z]|\b\w)/g, (word, index) => 
              index === 0 ? word.toLowerCase() : word.toUpperCase()
            ).replace(/\s+/g, '');
            break;
        }
      }
      result[key] = value;
    });
    return result;
  }

  // è¾…åŠ©æ–¹æ³•ï¼šç±»å‹è½¬æ¢
  private convertTypes(obj: any): any {
    const result = {};
    Object.keys(obj).forEach(key => {
      let value = obj[key];
      if (typeof value === 'string' && value.trim() !== '') {
        // å°è¯•è½¬æ¢ä¸ºæ•°å­—
        const numValue = Number(value);
        if (!isNaN(numValue) && isFinite(numValue)) {
          value = numValue;
        }
        // å°è¯•è½¬æ¢ä¸ºå¸ƒå°”å€¼
        else if (value.toLowerCase() === 'true') {
          value = true;
        } else if (value.toLowerCase() === 'false') {
          value = false;
        }
        // å°è¯•è½¬æ¢ä¸ºæ—¥æœŸ
        else if (Date.parse(value)) {
          value = new Date(value);
        }
      }
      result[key] = value;
    });
    return result;
  }

  // è¾…åŠ©æ–¹æ³•ï¼šåº”ç”¨å­—æ®µæ˜ å°„
  private async applyFieldMapping(data: any, mappings: any[]): Promise<any> {
    const result = { ...data };
    
    for (const mapping of mappings) {
      if (mapping.source && mapping.target) {
        let value = data[mapping.source];
        
        // åº”ç”¨è½¬æ¢å‡½æ•°
        if (mapping.transform && mapping.transform.trim()) {
          try {
            const transformFn = new Function('value', `return ${mapping.transform}`);
            value = transformFn(value);
          } catch (error) {
            throw new NodeOperationError(
              this.getNode(),
              `å­—æ®µæ˜ å°„è½¬æ¢å‡½æ•°é”™è¯¯: ${error.message}`,
              { description: `æ˜ å°„: ${mapping.source} -> ${mapping.target}` }
            );
          }
        }
        
        result[mapping.target] = value;
        
        // å¦‚æœç›®æ ‡å­—æ®µä¸æºå­—æ®µä¸åŒï¼Œåˆ é™¤æºå­—æ®µ
        if (mapping.source !== mapping.target) {
          delete result[mapping.source];
        }
      }
    }
    
    return result;
  }
}

#### ç¼“å­˜ç­–ç•¥å®ç°

```javascript
// Redisç¼“å­˜å®ç°
class WorkflowCache {
  constructor() {
    this.redis = require('redis').createClient({
      host: process.env.REDIS_HOST || 'localhost',
      port: process.env.REDIS_PORT || 6379,
      password: process.env.REDIS_PASSWORD
    });
  }

  // å¸¦TTLçš„ç¼“å­˜è®¾ç½®
  async set(key, value, ttlSeconds = 3600) {
    const serialized = JSON.stringify({
      data: value,
      timestamp: Date.now(),
      ttl: ttlSeconds
    });
    
    await this.redis.setex(key, ttlSeconds, serialized);
  }

  // æ™ºèƒ½ç¼“å­˜è·å–
  async get(key) {
    const cached = await this.redis.get(key);
    
    if (!cached) return null;
    
    try {
      const parsed = JSON.parse(cached);
      const age = (Date.now() - parsed.timestamp) / 1000;
      
      // å¦‚æœç¼“å­˜å³å°†è¿‡æœŸï¼Œå¼‚æ­¥åˆ·æ–°
      if (age > parsed.ttl * 0.8) {
        this.refreshCacheAsync(key);
      }
      
      return parsed.data;
    } catch (error) {
      await this.redis.del(key);
      return null;
    }
  }

  // æ‰¹é‡ç¼“å­˜æ“ä½œ
  async mget(keys) {
    const pipeline = this.redis.pipeline();
    keys.forEach(key => pipeline.get(key));
    
    const results = await pipeline.exec();
    
    return results.map((result, index) => {
      if (result[1]) {
        try {
          return JSON.parse(result[1]).data;
        } catch {
          return null;
        }
      }
      return null;
    });
  }

  // ç¼“å­˜æ¨¡å¼ï¼šè¯»ç©¿é€ä¿æŠ¤
  async getOrCompute(key, computeFn, ttl = 3600) {
    // é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
    let cached = await this.get(key);
    if (cached !== null) return cached;

    // ä½¿ç”¨åˆ†å¸ƒå¼é”é˜²æ­¢ç¼“å­˜å‡»ç©¿
    const lockKey = `lock:${key}`;
    const lockValue = Date.now().toString();
    
    const lockAcquired = await this.redis.set(
      lockKey, 
      lockValue, 
      'PX', 5000, // 5ç§’è¶…æ—¶
      'NX'  // åªåœ¨keyä¸å­˜åœ¨æ—¶è®¾ç½®
    );

    if (lockAcquired) {
      try {
        // è·å¾—é”ï¼Œè®¡ç®—å¹¶ç¼“å­˜ç»“æœ
        const computed = await computeFn();
        await this.set(key, computed, ttl);
        return computed;
      } finally {
        // é‡Šæ”¾é”
        const script = `
          if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
          else
            return 0
          end
        `;
        await this.redis.eval(script, 1, lockKey, lockValue);
      }
    } else {
      // æœªè·å¾—é”ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
      await new Promise(resolve => setTimeout(resolve, 100));
      return await this.getOrCompute(key, computeFn, ttl);
    }
  }
}

// åœ¨å·¥ä½œæµä¸­ä½¿ç”¨ç¼“å­˜
const cache = new WorkflowCache();

const getCachedUserData = async (userId) => {
  return await cache.getOrCompute(
    `user:${userId}`,
    async () => {
      // è¿™é‡Œæ˜¯å®é™…çš„æ•°æ®è·å–é€»è¾‘
      const userData = await $http.request({
        method: 'GET',
        url: `https://api.example.com/users/${userId}`,
        headers: { 'Authorization': `Bearer ${$credentials.apiToken}` }
      });
      
      return userData.data;
    },
    1800 // 30åˆ†é’Ÿç¼“å­˜
  );
};
```

### 2. æ€§èƒ½ç›‘æ§å®ç°

#### æ‰§è¡Œæ—¶é—´ç›‘æ§

```javascript
// æ€§èƒ½ç›‘æ§è£…é¥°å™¨
class PerformanceMonitor {
  constructor() {
    this.metrics = new Map();
    this.alerts = [];
  }

  // ç›‘æ§å‡½æ•°æ‰§è¡Œæ—¶é—´
  async measureExecution(name, fn, context = {}) {
    const startTime = process.hrtime.bigint();
    const startMemory = process.memoryUsage();
    
    try {
      const result = await fn();
      
      const endTime = process.hrtime.bigint();
      const endMemory = process.memoryUsage();
      
      const metrics = {
        name,
        context,
        duration: Number(endTime - startTime) / 1000000, // è½¬æ¢ä¸ºæ¯«ç§’
        memory: {
          heapUsed: endMemory.heapUsed - startMemory.heapUsed,
          heapTotal: endMemory.heapTotal - startMemory.heapTotal,
          external: endMemory.external - startMemory.external,
          rss: endMemory.rss - startMemory.rss
        },
        timestamp: new Date().toISOString(),
        success: true
      };
      
      this.recordMetrics(metrics);
      return result;
      
    } catch (error) {
      const endTime = process.hrtime.bigint();
      
      const metrics = {
        name,
        context,
        duration: Number(endTime - startTime) / 1000000,
        error: error.message,
        timestamp: new Date().toISOString(),
        success: false
      };
      
      this.recordMetrics(metrics);
      throw error;
    }
  }

  recordMetrics(metrics) {
    // å­˜å‚¨åˆ°æ—¶åºæ•°æ®åº“
    this.metrics.set(`${metrics.name}_${Date.now()}`, metrics);
    
    // æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
    this.checkThresholds(metrics);
    
    // å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
    this.sendToMonitoring(metrics);
  }

  checkThresholds(metrics) {
    const thresholds = {
      'api_call': { maxDuration: 5000, maxMemory: 50 * 1024 * 1024 },
      'data_processing': { maxDuration: 10000, maxMemory: 100 * 1024 * 1024 },
      'file_upload': { maxDuration: 30000, maxMemory: 200 * 1024 * 1024 }
    };

    const threshold = thresholds[metrics.name];
    if (!threshold) return;

    const alerts = [];
    
    if (metrics.duration > threshold.maxDuration) {
      alerts.push({
        type: 'performance',
        severity: 'warning',
        message: `${metrics.name} æ‰§è¡Œæ—¶é—´è¶…è¿‡é˜ˆå€¼`,
        details: {
          actual: metrics.duration,
          threshold: threshold.maxDuration,
          context: metrics.context
        }
      });
    }

    if (metrics.memory?.heapUsed > threshold.maxMemory) {
      alerts.push({
        type: 'memory',
        severity: 'warning', 
        message: `${metrics.name} å†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼`,
        details: {
          actual: metrics.memory.heapUsed,
          threshold: threshold.maxMemory,
          context: metrics.context
        }
      });
    }

    this.alerts.push(...alerts);
  }

  async sendToMonitoring(metrics) {
    // å‘é€åˆ°Prometheus
    if (process.env.PROMETHEUS_GATEWAY) {
      await this.sendToPrometheus(metrics);
    }
    
    // å‘é€åˆ°DataDog
    if (process.env.DATADOG_API_KEY) {
      await this.sendToDataDog(metrics);
    }
    
    // å‘é€åˆ°è‡ªå®šä¹‰ç›‘æ§ç«¯ç‚¹
    if (process.env.CUSTOM_METRICS_URL) {
      await this.sendToCustomEndpoint(metrics);
    }
  }

  async sendToPrometheus(metrics) {
    const gateway = require('prom-client').Pushgateway;
    const pushgateway = new gateway(process.env.PROMETHEUS_GATEWAY);
    
    const register = require('prom-client').register;
    const histogram = new require('prom-client').Histogram({
      name: 'n8n_workflow_execution_duration_seconds',
      help: 'Duration of workflow executions',
      labelNames: ['workflow_name', 'node_name', 'status'],
      buckets: [0.1, 0.5, 1, 2, 5, 10, 30, 60]
    });
    
    histogram.observe(
      {
        workflow_name: metrics.context.workflowName || 'unknown',
        node_name: metrics.name,
        status: metrics.success ? 'success' : 'error'
      },
      metrics.duration / 1000
    );

    await pushgateway.pushAdd({ jobName: 'n8n_workflows' });
  }
}

// åœ¨å·¥ä½œæµä¸­ä½¿ç”¨ç›‘æ§
const monitor = new PerformanceMonitor();

const result = await monitor.measureExecution(
  'api_call',
  async () => {
    return await $http.request({
      method: 'POST',
      url: 'https://api.example.com/data',
      body: $json,
      timeout: 10000
    });
  },
  {
    workflowName: $workflow.name,
    executionId: $execution.id,
    nodeType: 'http_request'
  }
);
```

#### é”™è¯¯ç›‘æ§å’Œå‘Šè­¦

```javascript
// é”™è¯¯ç›‘æ§ç³»ç»Ÿ
class ErrorMonitor {
  constructor() {
    this.errorCounts = new Map();
    this.errorPatterns = new Map();
    this.alertThresholds = {
      errorRate: 0.1, // 10%é”™è¯¯ç‡è§¦å‘å‘Šè­¦
      consecutiveErrors: 5, // è¿ç»­5æ¬¡é”™è¯¯è§¦å‘å‘Šè­¦
      timeWindow: 300000 // 5åˆ†é’Ÿæ—¶é—´çª—å£
    };
  }

  recordError(error, context = {}) {
    const errorKey = this.generateErrorKey(error);
    const timestamp = Date.now();
    
    // è®°å½•é”™è¯¯ç»Ÿè®¡
    if (!this.errorCounts.has(errorKey)) {
      this.errorCounts.set(errorKey, []);
    }
    
    this.errorCounts.get(errorKey).push({
      timestamp,
      error: error.message,
      stack: error.stack,
      context
    });
    
    // æ¸…ç†è¿‡æœŸé”™è¯¯è®°å½•
    this.cleanupOldErrors(errorKey);
    
    // æ£€æŸ¥å‘Šè­¦æ¡ä»¶
    this.checkAlertConditions(errorKey, error, context);
  }

  generateErrorKey(error) {
    // æ ¹æ®é”™è¯¯ç±»å‹å’Œæ¶ˆæ¯ç”Ÿæˆå”¯ä¸€æ ‡è¯†
    const errorType = error.constructor.name;
    const messagePattern = error.message.replace(/\d+/g, 'NUMBER').replace(/[a-f0-9-]{36}/g, 'UUID');
    return `${errorType}:${messagePattern}`;
  }

  cleanupOldErrors(errorKey) {
    const now = Date.now();
    const errors = this.errorCounts.get(errorKey);
    const validErrors = errors.filter(e => now - e.timestamp < this.alertThresholds.timeWindow);
    this.errorCounts.set(errorKey, validErrors);
  }

  checkAlertConditions(errorKey, error, context) {
    const errors = this.errorCounts.get(errorKey);
    const now = Date.now();
    
    // æ£€æŸ¥é”™è¯¯ç‡
    const recentExecutions = this.getRecentExecutions(context.workflowId);
    const errorRate = errors.length / recentExecutions;
    
    if (errorRate >= this.alertThresholds.errorRate) {
      this.sendAlert({
        type: 'high_error_rate',
        severity: 'critical',
        message: `å·¥ä½œæµ ${context.workflowName} é”™è¯¯ç‡è¿‡é«˜: ${(errorRate * 100).toFixed(2)}%`,
        details: {
          errorKey,
          errorCount: errors.length,
          totalExecutions: recentExecutions,
          timeWindow: this.alertThresholds.timeWindow / 1000 / 60 // åˆ†é’Ÿ
        }
      });
    }
    
    // æ£€æŸ¥è¿ç»­é”™è¯¯
    const consecutiveErrors = this.getConsecutiveErrors(context.workflowId);
    if (consecutiveErrors >= this.alertThresholds.consecutiveErrors) {
      this.sendAlert({
        type: 'consecutive_errors',
        severity: 'critical',
        message: `å·¥ä½œæµ ${context.workflowName} è¿ç»­ ${consecutiveErrors} æ¬¡æ‰§è¡Œå¤±è´¥`,
        details: {
          workflowId: context.workflowId,
          consecutiveErrors,
          lastError: error.message
        }
      });
    }
  }

  async sendAlert(alert) {
    // å‘é€åˆ°Slack
    if (process.env.SLACK_WEBHOOK_URL) {
      await this.sendSlackAlert(alert);
    }
    
    // å‘é€åˆ°é‚®ä»¶
    if (process.env.ALERT_EMAIL) {
      await this.sendEmailAlert(alert);
    }
    
    // å‘é€åˆ°PagerDuty
    if (process.env.PAGERDUTY_INTEGRATION_KEY) {
      await this.sendPagerDutyAlert(alert);
    }
  }

  async sendSlackAlert(alert) {
    const webhook = require('@slack/webhook');
    const url = process.env.SLACK_WEBHOOK_URL;
    
    const slackWebhook = new webhook.IncomingWebhook(url);
    
    const color = {
      'critical': 'danger',
      'warning': 'warning',
      'info': 'good'
    }[alert.severity] || 'warning';
    
    await slackWebhook.send({
      attachments: [{
        color,
        title: `ğŸš¨ n8nå·¥ä½œæµå‘Šè­¦ - ${alert.severity.toUpperCase()}`,
        text: alert.message,
        fields: [
          {
            title: 'å‘Šè­¦ç±»å‹',
            value: alert.type,
            short: true
          },
          {
            title: 'æ—¶é—´',
            value: new Date().toLocaleString('zh-CN'),
            short: true
          }
        ],
        footer: 'n8nç›‘æ§ç³»ç»Ÿ'
      }]
    });
  }
}

// åœ¨å·¥ä½œæµä¸­é›†æˆé”™è¯¯ç›‘æ§
const errorMonitor = new ErrorMonitor();

try {
  // æ‰§è¡Œä¸šåŠ¡é€»è¾‘
  const result = await processData($json);
  return result;
} catch (error) {
  // è®°å½•é”™è¯¯
  errorMonitor.recordError(error, {
    workflowId: $workflow.id,
    workflowName: $workflow.name,
    executionId: $execution.id,
    nodeId: $node.id,
    nodeName: $node.name
  });
  
  // é‡æ–°æŠ›å‡ºé”™è¯¯æˆ–è¿”å›é»˜è®¤å€¼
  if (this.continueOnFail()) {
    return { error: error.message, failed: true };
  } else {
    throw error;
  }
}
```

### 3. èµ„æºä½¿ç”¨ä¼˜åŒ–

#### æ•°æ®åº“è¿æ¥æ± ç®¡ç†

```javascript
// æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
class DatabasePool {
  constructor(config) {
    this.pools = new Map();
    this.config = {
      min: 2,
      max: 20,
      acquireTimeoutMillis: 30000,
      createTimeoutMillis: 30000,
      destroyTimeoutMillis: 5000,
      idleTimeoutMillis: 30000,
      reapIntervalMillis: 1000,
      createRetryIntervalMillis: 200,
      ...config
    };
  }

  async getConnection(database) {
    if (!this.pools.has(database)) {
      const knex = require('knex')({
        client: 'mysql2',
        connection: {
          host: process.env.DB_HOST,
          user: process.env.DB_USER,
          password: process.env.DB_PASSWORD,
          database: database
        },
        pool: this.config,
        acquireConnectionTimeout: this.config.acquireTimeoutMillis
      });
      
      this.pools.set(database, knex);
    }
    
    return this.pools.get(database);
  }

  async executeQuery(database, query, params = []) {
    const connection = await this.getConnection(database);
    
    const startTime = Date.now();
    try {
      const result = await connection.raw(query, params);
      const duration = Date.now() - startTime;
      
      // è®°å½•æŸ¥è¯¢æ€§èƒ½
      if (duration > 1000) {
        console.warn(`æ…¢æŸ¥è¯¢æ£€æµ‹: ${duration}ms`, { query, params });
      }
      
      return result[0];
    } catch (error) {
      console.error(`æ•°æ®åº“æŸ¥è¯¢é”™è¯¯:`, { query, params, error: error.message });
      throw error;
    }
  }

  async healthCheck() {
    const health = {};
    
    for (const [database, pool] of this.pools) {
      try {
        await pool.raw('SELECT 1 as health');
        health[database] = {
          status: 'healthy',
          connections: {
            used: pool.client.pool.numUsed(),
            free: pool.client.pool.numFree(),
            pending: pool.client.pool.numPendingAcquires(),
            max: this.config.max
          }
        };
      } catch (error) {
        health[database] = {
          status: 'unhealthy',
          error: error.message
        };
      }
    }
    
    return health;
  }

  async cleanup() {
    for (const [database, pool] of this.pools) {
      await pool.destroy();
    }
    this.pools.clear();
  }
}

// å…¨å±€æ•°æ®åº“æ± å®ä¾‹
const dbPool = new DatabasePool();

// åœ¨å·¥ä½œæµä¸­ä½¿ç”¨
const userData = await dbPool.executeQuery(
  'user_database',
  'SELECT * FROM users WHERE status = ? AND created_at > ?',
  ['active', new Date(Date.now() - 30 * 24 * 60 * 60 * 1000)]
);
```

é€šè¿‡å®æ–½è¿™äº›æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§ç­–ç•¥ï¼Œæ‚¨å¯ä»¥ç¡®ä¿n8nå·¥ä½œæµåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šã€é«˜æ•ˆåœ°è¿è¡Œï¼Œå¹¶åŠæ—¶å‘ç°å’Œè§£å†³æ€§èƒ½é—®é¢˜ã€‚ 

## ä¼ä¸šçº§è¿ç»´å®è·µ

åœ¨ä¼ä¸šç¯å¢ƒä¸­éƒ¨ç½²å’Œè¿ç»´n8néœ€è¦è€ƒè™‘é«˜å¯ç”¨æ€§ã€å®‰å…¨æ€§ã€å¯æ‰©å±•æ€§å’Œåˆè§„æ€§ç­‰å¤šä¸ªæ–¹é¢ã€‚æœ¬èŠ‚æä¾›ä¼ä¸šçº§n8nè¿ç»´çš„æœ€ä½³å®è·µã€‚

### 1. é«˜å¯ç”¨æ€§æ¶æ„

#### å¤šèŠ‚ç‚¹é›†ç¾¤é…ç½®

```yaml
# docker-compose-ha.yml - é«˜å¯ç”¨é…ç½®
version: '3.8'

services:
  # è´Ÿè½½å‡è¡¡å™¨
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - n8n-main-1
      - n8n-main-2
    restart: unless-stopped

  # ä¸»èŠ‚ç‚¹é›†ç¾¤
  n8n-main-1:
    image: n8nio/n8n
    environment:
      - N8N_HOST=n8n.company.com
      - N8N_PROTOCOL=https
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres-primary
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=${DB_PASSWORD}
      - EXECUTIONS_MODE=queue
      - QUEUE_BULL_REDIS_HOST=redis-cluster
      - N8N_ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - GENERIC_TIMEZONE=Asia/Shanghai
      - N8N_METRICS=true
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_VERSION_NOTIFICATIONS_ENABLED=false
      - N8N_TEMPLATES_ENABLED=false
      - N8N_ONBOARDING_FLOW_DISABLED=true
      - N8N_PERSONALIZATION_ENABLED=false
    volumes:
      - n8n-main-1-data:/home/node/.n8n
      - ./custom-nodes:/home/node/custom-nodes:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  n8n-main-2:
    image: n8nio/n8n
    environment:
      - N8N_HOST=n8n.company.com
      - N8N_PROTOCOL=https
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres-primary
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=${DB_PASSWORD}
      - EXECUTIONS_MODE=queue
      - QUEUE_BULL_REDIS_HOST=redis-cluster
      - N8N_ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - GENERIC_TIMEZONE=Asia/Shanghai
      - N8N_METRICS=true
    volumes:
      - n8n-main-2-data:/home/node/.n8n
      - ./custom-nodes:/home/node/custom-nodes:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # å·¥ä½œèŠ‚ç‚¹é›†ç¾¤
  n8n-worker-1:
    image: n8nio/n8n
    command: n8n worker
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres-primary
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=${DB_PASSWORD}
      - QUEUE_BULL_REDIS_HOST=redis-cluster
      - N8N_ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - EXECUTIONS_PROCESS=main
      - N8N_METRICS=true
    volumes:
      - ./custom-nodes:/home/node/custom-nodes:ro
    restart: unless-stopped
    deploy:
      replicas: 3

  # PostgreSQLä¸»ä»å¤åˆ¶
  postgres-primary:
    image: postgres:13
    environment:
      - POSTGRES_DB=n8n
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_REPLICATION_MODE=master
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
    volumes:
      - postgres-primary-data:/var/lib/postgresql/data
      - ./postgres/primary.conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    restart: unless-stopped

  postgres-replica:
    image: postgres:13
    environment:
      - POSTGRES_MASTER_SERVICE=postgres-primary
      - POSTGRES_REPLICATION_MODE=slave
      - POSTGRES_REPLICATION_USER=replicator
      - POSTGRES_REPLICATION_PASSWORD=${REPLICATION_PASSWORD}
      - POSTGRES_MASTER_PORT_NUMBER=5432
    volumes:
      - postgres-replica-data:/var/lib/postgresql/data
    restart: unless-stopped

  # Redisé›†ç¾¤
  redis-cluster:
    image: redis/redis-stack:latest
    ports:
      - "6379:6379"
    environment:
      - REDIS_ARGS=--appendonly yes --cluster-enabled yes
    volumes:
      - redis-cluster-data:/data
    restart: unless-stopped

  # ç›‘æ§ç»„ä»¶
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped

volumes:
  n8n-main-1-data:
  n8n-main-2-data:
  postgres-primary-data:
  postgres-replica-data:
  redis-cluster-data:
  prometheus-data:
  grafana-data:
```

#### Nginxè´Ÿè½½å‡è¡¡é…ç½®

```nginx
# nginx/nginx.conf
upstream n8n_backend {
    least_conn;
    server n8n-main-1:5678 max_fails=3 fail_timeout=30s;
    server n8n-main-2:5678 max_fails=3 fail_timeout=30s;
    
    # å¥åº·æ£€æŸ¥
    keepalive 32;
}

upstream n8n_webhook {
    ip_hash;  # Webhookéœ€è¦ä¼šè¯ä¿æŒ
    server n8n-main-1:5678;
    server n8n-main-2:5678;
}

server {
    listen 80;
    server_name n8n.company.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name n8n.company.com;

    # SSLé…ç½®
    ssl_certificate /etc/nginx/ssl/n8n.crt;
    ssl_certificate_key /etc/nginx/ssl/n8n.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256;
    ssl_prefer_server_ciphers off;

    # å®‰å…¨å¤´
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    # ä¸»åº”ç”¨
    location / {
        proxy_pass http://n8n_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # è¶…æ—¶è®¾ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # ç¼“å†²è®¾ç½®
        proxy_buffering on;
        proxy_buffer_size 128k;
        proxy_buffers 4 256k;
        proxy_busy_buffers_size 256k;
    }

    # Webhookè·¯ç”±
    location /webhook/ {
        proxy_pass http://n8n_webhook;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Webhookç‰¹æ®Šé…ç½®
        proxy_read_timeout 300s;
        client_max_body_size 50m;
    }

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹
    location /healthz {
        proxy_pass http://n8n_backend/healthz;
        access_log off;
    }

    # é™æ€èµ„æºç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        proxy_pass http://n8n_backend;
        proxy_cache_valid 200 1d;
        add_header Cache-Control "public, immutable";
    }
}
```

### 2. å®‰å…¨ç®¡ç†

#### ä¼ä¸šçº§èº«ä»½éªŒè¯

```typescript
// SAML SSOé›†æˆç¤ºä¾‹
import { Strategy as SamlStrategy } from 'passport-saml';
import passport from 'passport';

class EnterpriseAuth {
  constructor() {
    this.initSAML();
    this.initOIDC();
    this.initLDAP();
  }

  initSAML() {
    passport.use(new SamlStrategy({
      path: '/auth/saml/callback',
      entryPoint: process.env.SAML_ENTRY_POINT,
      issuer: process.env.SAML_ISSUER,
      cert: process.env.SAML_CERT,
      signatureAlgorithm: 'sha256',
      digestAlgorithm: 'sha256',
    }, async (profile, done) => {
      try {
        const user = await this.processUserProfile(profile);
        return done(null, user);
      } catch (error) {
        return done(error);
      }
    }));
  }

  async processUserProfile(profile) {
    const userInfo = {
      id: profile.nameID,
      email: profile.email || profile['http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress'],
      firstName: profile.firstName || profile['http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname'],
      lastName: profile.lastName || profile['http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname'],
      roles: this.extractRoles(profile),
      department: profile.department,
      manager: profile.manager
    };

    // è§’è‰²æ˜ å°„å’Œæƒé™åˆ†é…
    const n8nRoles = this.mapToN8nRoles(userInfo.roles);
    
    // åˆ›å»ºæˆ–æ›´æ–°ç”¨æˆ·
    const user = await this.createOrUpdateUser(userInfo, n8nRoles);
    
    // è®°å½•å®¡è®¡æ—¥å¿—
    await this.auditLog('user_login', {
      userId: user.id,
      email: user.email,
      roles: n8nRoles,
      loginMethod: 'saml',
      timestamp: new Date().toISOString()
    });

    return user;
  }

  mapToN8nRoles(externalRoles) {
    const roleMapping = {
      'IT_ADMIN': ['admin'],
      'WORKFLOW_MANAGER': ['editor', 'user'],
      'BUSINESS_USER': ['user'],
      'AUDITOR': ['viewer']
    };

    const n8nRoles = [];
    externalRoles.forEach(role => {
      if (roleMapping[role]) {
        n8nRoles.push(...roleMapping[role]);
      }
    });

    return [...new Set(n8nRoles)]; // å»é‡
  }
}
```

#### æ•°æ®åŠ å¯†å’Œå¯†é’¥ç®¡ç†

```typescript
// ä¼ä¸šçº§å¯†é’¥ç®¡ç†
class KeyManagement {
  constructor() {
    this.vaultClient = this.initVault();
    this.rotationSchedule = new Map();
  }

  async initVault() {
    const vault = require('node-vault')({
      apiVersion: 'v1',
      endpoint: process.env.VAULT_ENDPOINT,
      token: process.env.VAULT_TOKEN
    });

    // éªŒè¯è¿æ¥
    await vault.read('sys/health');
    return vault;
  }

  async getEncryptionKey(keyId) {
    try {
      const result = await this.vaultClient.read(`secret/data/n8n/keys/${keyId}`);
      return result.data.data.key;
    } catch (error) {
      throw new Error(`æ— æ³•è·å–åŠ å¯†å¯†é’¥: ${error.message}`);
    }
  }

  async rotateKey(keyId) {
    const newKey = this.generateKey();
    
    // ä¿å­˜æ–°å¯†é’¥
    await this.vaultClient.write(`secret/data/n8n/keys/${keyId}`, {
      data: {
        key: newKey,
        created: new Date().toISOString(),
        version: await this.getNextVersion(keyId)
      }
    });

    // æ›´æ–°å·¥ä½œæµä¸­çš„å¯†é’¥å¼•ç”¨
    await this.updateWorkflowCredentials(keyId, newKey);
    
    // è®°å½•å¯†é’¥è½®æ¢äº‹ä»¶
    await this.auditLog('key_rotation', {
      keyId,
      timestamp: new Date().toISOString(),
      initiator: 'system'
    });

    return newKey;
  }

  generateKey() {
    const crypto = require('crypto');
    return crypto.randomBytes(32).toString('hex');
  }

  // è‡ªåŠ¨å¯†é’¥è½®æ¢
  scheduleKeyRotation(keyId, intervalDays = 90) {
    const interval = intervalDays * 24 * 60 * 60 * 1000;
    
    const rotationTimer = setInterval(async () => {
      try {
        await this.rotateKey(keyId);
        console.log(`å¯†é’¥ ${keyId} è½®æ¢æˆåŠŸ`);
      } catch (error) {
        console.error(`å¯†é’¥ ${keyId} è½®æ¢å¤±è´¥:`, error);
        // å‘é€å‘Šè­¦
        await this.sendAlert('key_rotation_failed', {
          keyId,
          error: error.message
        });
      }
    }, interval);

    this.rotationSchedule.set(keyId, rotationTimer);
  }

  // æ•°æ®åº“å­—æ®µçº§åŠ å¯†
  async encryptSensitiveField(data, fieldName, keyId) {
    const key = await this.getEncryptionKey(keyId);
    const crypto = require('crypto');
    
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipher('aes-256-gcm', key, iv);
    
    let encrypted = cipher.update(data[fieldName], 'utf8', 'hex');
    encrypted += cipher.final('hex');
    
    const authTag = cipher.getAuthTag();
    
    return {
      ...data,
      [fieldName]: {
        encrypted: encrypted,
        iv: iv.toString('hex'),
        authTag: authTag.toString('hex'),
        keyId: keyId
      }
    };
  }

  async decryptSensitiveField(data, fieldName) {
    if (!data[fieldName] || typeof data[fieldName] !== 'object') {
      return data; // å­—æ®µæœªåŠ å¯†
    }

    const encryptedData = data[fieldName];
    const key = await this.getEncryptionKey(encryptedData.keyId);
    const crypto = require('crypto');
    
    const decipher = crypto.createDecipher('aes-256-gcm', key, Buffer.from(encryptedData.iv, 'hex'));
    decipher.setAuthTag(Buffer.from(encryptedData.authTag, 'hex'));
    
    let decrypted = decipher.update(encryptedData.encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    
    return {
      ...data,
      [fieldName]: decrypted
    };
  }
}
```

### 3. å®¡è®¡å’Œåˆè§„

#### å®¡è®¡æ—¥å¿—ç³»ç»Ÿ

```typescript
// å…¨é¢çš„å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
class AuditLogger {
  constructor() {
    this.logStream = this.initLogStream();
    this.complianceChecks = new Map();
  }

  async initLogStream() {
    if (process.env.ELASTICSEARCH_URL) {
      return this.initElasticsearch();
    } else if (process.env.SPLUNK_URL) {
      return this.initSplunk();
    } else {
      return this.initFileLogger();
    }
  }

  async log(event, details = {}) {
    const auditEntry = {
      timestamp: new Date().toISOString(),
      event,
      details,
      sessionId: details.sessionId || 'system',
      userId: details.userId || 'system',
      userAgent: details.userAgent,
      ipAddress: details.ipAddress,
      workflowId: details.workflowId,
      nodeId: details.nodeId,
      executionId: details.executionId,
      severity: this.calculateSeverity(event),
      compliance: {
        gdpr: this.checkGDPRCompliance(event, details),
        sox: this.checkSOXCompliance(event, details),
        pci: this.checkPCICompliance(event, details)
      }
    };

    // è®°å½•åˆ°æ—¥å¿—ç³»ç»Ÿ
    await this.writeToLogStream(auditEntry);

    // å®æ—¶åˆè§„æ£€æŸ¥
    await this.performComplianceChecks(auditEntry);

    // æ•æ„Ÿäº‹ä»¶å³æ—¶å‘Šè­¦
    if (this.isSensitiveEvent(event)) {
      await this.sendSecurityAlert(auditEntry);
    }
  }

  calculateSeverity(event) {
    const severityMap = {
      'user_login': 'info',
      'user_logout': 'info',
      'workflow_created': 'info',
      'workflow_modified': 'warn',
      'workflow_deleted': 'warn',
      'credential_accessed': 'warn',
      'credential_modified': 'error',
      'admin_action': 'error',
      'failed_login': 'warn',
      'multiple_failed_logins': 'error',
      'data_export': 'warn',
      'api_key_created': 'warn',
      'api_key_deleted': 'error'
    };

    return severityMap[event] || 'info';
  }

  checkGDPRCompliance(event, details) {
    const gdprEvents = [
      'personal_data_accessed',
      'personal_data_modified',
      'personal_data_deleted',
      'data_export',
      'consent_granted',
      'consent_revoked'
    ];

    return {
      applicable: gdprEvents.includes(event),
      dataSubject: details.dataSubject,
      legalBasis: details.legalBasis,
      retentionPeriod: details.retentionPeriod,
      encrypted: details.encrypted || false
    };
  }

  async performComplianceChecks(auditEntry) {
    // æ•°æ®ä¿ç•™æ”¿ç­–æ£€æŸ¥
    if (auditEntry.event === 'personal_data_accessed') {
      await this.checkDataRetention(auditEntry);
    }

    // è®¿é—®é¢‘ç‡å¼‚å¸¸æ£€æµ‹
    if (auditEntry.event === 'credential_accessed') {
      await this.checkAccessFrequency(auditEntry);
    }

    // æƒé™åˆ†ç¦»æ£€æŸ¥
    if (auditEntry.event === 'admin_action') {
      await this.checkSeparationOfDuties(auditEntry);
    }
  }

  async generateComplianceReport(type, startDate, endDate) {
    const query = {
      startDate,
      endDate,
      complianceType: type
    };

    const events = await this.queryAuditLogs(query);
    
    const report = {
      reportType: type,
      period: { startDate, endDate },
      summary: {
        totalEvents: events.length,
        eventsByType: this.groupEventsByType(events),
        userActivity: this.analyzeUserActivity(events),
        complianceViolations: this.findComplianceViolations(events, type)
      },
      recommendations: this.generateRecommendations(events, type),
      generatedAt: new Date().toISOString()
    };

    // ä¿å­˜æŠ¥å‘Š
    await this.saveComplianceReport(report);
    
    return report;
  }

  findComplianceViolations(events, complianceType) {
    const violations = [];

    events.forEach(event => {
      switch (complianceType) {
        case 'gdpr':
          if (this.isGDPRViolation(event)) {
            violations.push({
              type: 'gdpr_violation',
              event: event.event,
              details: event.details,
              timestamp: event.timestamp,
              severity: 'high'
            });
          }
          break;

        case 'sox':
          if (this.isSOXViolation(event)) {
            violations.push({
              type: 'sox_violation',
              event: event.event,
              details: event.details,
              timestamp: event.timestamp,
              severity: 'critical'
            });
          }
          break;

        case 'pci':
          if (this.isPCIViolation(event)) {
            violations.push({
              type: 'pci_violation',
              event: event.event,
              details: event.details,
              timestamp: event.timestamp,
              severity: 'high'
            });
          }
          break;
      }
    });

    return violations;
  }
}
```

### 4. å¤‡ä»½å’Œç¾éš¾æ¢å¤

#### è‡ªåŠ¨åŒ–å¤‡ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup-n8n.sh - è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

set -euo pipefail

# é…ç½®
BACKUP_DIR="/opt/n8n-backups"
RETENTION_DAYS=30
S3_BUCKET="company-n8n-backups"
ENCRYPTION_KEY_FILE="/etc/n8n/backup.key"

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a /var/log/n8n-backup.log
}

# åˆ›å»ºå¤‡ä»½ç›®å½•
create_backup_dir() {
    local backup_date=$(date '+%Y%m%d-%H%M%S')
    local backup_path="${BACKUP_DIR}/${backup_date}"
    mkdir -p "${backup_path}"
    echo "${backup_path}"
}

# æ•°æ®åº“å¤‡ä»½
backup_database() {
    local backup_path=$1
    log "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
    
    # PostgreSQLå¤‡ä»½
    PGPASSWORD=${DB_PASSWORD} pg_dump \
        -h ${DB_HOST} \
        -U ${DB_USER} \
        -d ${DB_NAME} \
        --no-owner \
        --no-privileges \
        --create \
        --clean \
        --if-exists \
        > "${backup_path}/database.sql"
    
    # å‹ç¼©æ•°æ®åº“å¤‡ä»½
    gzip "${backup_path}/database.sql"
    
    log "æ•°æ®åº“å¤‡ä»½å®Œæˆ: ${backup_path}/database.sql.gz"
}

# å·¥ä½œæµå¤‡ä»½
backup_workflows() {
    local backup_path=$1
    log "å¼€å§‹å·¥ä½œæµå¤‡ä»½..."
    
    # å¯¼å‡ºæ‰€æœ‰å·¥ä½œæµ
    docker exec n8n-main-1 n8n export:workflow \
        --backup \
        --output=/tmp/workflows-backup.json
    
    # å¤åˆ¶åˆ°å¤‡ä»½ç›®å½•
    docker cp n8n-main-1:/tmp/workflows-backup.json "${backup_path}/"
    
    # å¯¼å‡ºå‡­æ®æ¨¡æ¿ï¼ˆä¸åŒ…å«å®é™…å¯†é’¥ï¼‰
    docker exec n8n-main-1 n8n export:credentials \
        --backup \
        --output=/tmp/credentials-backup.json
    
    docker cp n8n-main-1:/tmp/credentials-backup.json "${backup_path}/"
    
    log "å·¥ä½œæµå¤‡ä»½å®Œæˆ"
}

# é…ç½®å¤‡ä»½
backup_config() {
    local backup_path=$1
    log "å¼€å§‹é…ç½®å¤‡ä»½..."
    
    # Docker Composeé…ç½®
    cp docker-compose.yml "${backup_path}/"
    cp .env "${backup_path}/"
    
    # Nginxé…ç½®
    cp -r nginx/ "${backup_path}/"
    
    # è‡ªå®šä¹‰èŠ‚ç‚¹
    if [ -d "custom-nodes" ]; then
        cp -r custom-nodes/ "${backup_path}/"
    fi
    
    log "é…ç½®å¤‡ä»½å®Œæˆ"
}

# åŠ å¯†å¤‡ä»½
encrypt_backup() {
    local backup_path=$1
    log "å¼€å§‹åŠ å¯†å¤‡ä»½..."
    
    cd "${BACKUP_DIR}"
    local backup_name=$(basename "${backup_path}")
    
    # åˆ›å»ºå‹ç¼©åŒ…
    tar -czf "${backup_name}.tar.gz" "${backup_name}/"
    
    # åŠ å¯†
    openssl enc -aes-256-cbc -salt \
        -in "${backup_name}.tar.gz" \
        -out "${backup_name}.tar.gz.enc" \
        -pass file:"${ENCRYPTION_KEY_FILE}"
    
    # åˆ é™¤æœªåŠ å¯†çš„æ–‡ä»¶
    rm -rf "${backup_name}/" "${backup_name}.tar.gz"
    
    log "å¤‡ä»½åŠ å¯†å®Œæˆ: ${backup_name}.tar.gz.enc"
}

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
upload_to_cloud() {
    local backup_file=$1
    log "å¼€å§‹ä¸Šä¼ åˆ°äº‘å­˜å‚¨..."
    
    aws s3 cp "${backup_file}" "s3://${S3_BUCKET}/$(basename ${backup_file})" \
        --storage-class STANDARD_IA \
        --server-side-encryption AES256
    
    # éªŒè¯ä¸Šä¼ 
    if aws s3 ls "s3://${S3_BUCKET}/$(basename ${backup_file})" > /dev/null; then
        log "äº‘å­˜å‚¨ä¸Šä¼ æˆåŠŸ"
        return 0
    else
        log "é”™è¯¯: äº‘å­˜å‚¨ä¸Šä¼ å¤±è´¥"
        return 1
    fi
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    log "å¼€å§‹æ¸…ç†æ—§å¤‡ä»½..."
    
    # æœ¬åœ°æ¸…ç†
    find "${BACKUP_DIR}" -name "*.tar.gz.enc" -mtime +${RETENTION_DAYS} -delete
    
    # S3æ¸…ç†ï¼ˆä½¿ç”¨ç”Ÿå‘½å‘¨æœŸç­–ç•¥æ›´å¥½ï¼‰
    aws s3 ls "s3://${S3_BUCKET}/" --recursive | \
    while read -r line; do
        file_date=$(echo "$line" | awk '{print $1}')
        file_name=$(echo "$line" | awk '{print $4}')
        
        if [[ $(date -d "$file_date" +%s) -lt $(date -d "${RETENTION_DAYS} days ago" +%s) ]]; then
            aws s3 rm "s3://${S3_BUCKET}/${file_name}"
            log "åˆ é™¤æ—§å¤‡ä»½: ${file_name}"
        fi
    done
    
    log "æ—§å¤‡ä»½æ¸…ç†å®Œæˆ"
}

# å¤‡ä»½éªŒè¯
verify_backup() {
    local backup_file=$1
    log "å¼€å§‹å¤‡ä»½éªŒè¯..."
    
    # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    if [ ! -f "${backup_file}" ]; then
        log "é”™è¯¯: å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        return 1
    fi
    
    # æ£€æŸ¥åŠ å¯†æ–‡ä»¶å¯ä»¥è§£å¯†
    local temp_dir=$(mktemp -d)
    openssl enc -aes-256-cbc -d \
        -in "${backup_file}" \
        -out "${temp_dir}/test.tar.gz" \
        -pass file:"${ENCRYPTION_KEY_FILE}"
    
    if [ $? -eq 0 ]; then
        log "å¤‡ä»½éªŒè¯æˆåŠŸ"
        rm -rf "${temp_dir}"
        return 0
    else
        log "é”™è¯¯: å¤‡ä»½éªŒè¯å¤±è´¥"
        rm -rf "${temp_dir}"
        return 1
    fi
}

# å‘é€é€šçŸ¥
send_notification() {
    local status=$1
    local message=$2
    
    if [ "${status}" = "success" ]; then
        # å‘é€æˆåŠŸé€šçŸ¥åˆ°Slack
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"âœ… n8nå¤‡ä»½æˆåŠŸ: ${message}\"}" \
            "${SLACK_WEBHOOK_URL}"
    else
        # å‘é€å¤±è´¥å‘Šè­¦
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"âŒ n8nå¤‡ä»½å¤±è´¥: ${message}\"}" \
            "${SLACK_WEBHOOK_URL}"
        
        # å‘é€é‚®ä»¶å‘Šè­¦
        echo "${message}" | mail -s "n8nå¤‡ä»½å¤±è´¥å‘Šè­¦" "${ALERT_EMAIL}"
    fi
}

# ä¸»å¤‡ä»½æµç¨‹
main() {
    log "å¼€å§‹n8nå¤‡ä»½æµç¨‹..."
    
    local backup_path=$(create_backup_dir)
    local backup_success=true
    local error_message=""
    
    # æ‰§è¡Œå¤‡ä»½æ­¥éª¤
    if ! backup_database "${backup_path}"; then
        backup_success=false
        error_message="æ•°æ®åº“å¤‡ä»½å¤±è´¥"
    elif ! backup_workflows "${backup_path}"; then
        backup_success=false
        error_message="å·¥ä½œæµå¤‡ä»½å¤±è´¥"
    elif ! backup_config "${backup_path}"; then
        backup_success=false
        error_message="é…ç½®å¤‡ä»½å¤±è´¥"
    elif ! encrypt_backup "${backup_path}"; then
        backup_success=false
        error_message="å¤‡ä»½åŠ å¯†å¤±è´¥"
    else
        local encrypted_file="${backup_path}.tar.gz.enc"
        
        if ! verify_backup "${encrypted_file}"; then
            backup_success=false
            error_message="å¤‡ä»½éªŒè¯å¤±è´¥"
        elif ! upload_to_cloud "${encrypted_file}"; then
            backup_success=false
            error_message="äº‘å­˜å‚¨ä¸Šä¼ å¤±è´¥"
        fi
    fi
    
    # æ¸…ç†æ—§å¤‡ä»½
    cleanup_old_backups
    
    # å‘é€é€šçŸ¥
    if [ "${backup_success}" = true ]; then
        log "n8nå¤‡ä»½æµç¨‹æˆåŠŸå®Œæˆ"
        send_notification "success" "å¤‡ä»½æ–‡ä»¶: $(basename ${backup_path}).tar.gz.enc"
    else
        log "é”™è¯¯: n8nå¤‡ä»½æµç¨‹å¤±è´¥ - ${error_message}"
        send_notification "failure" "${error_message}"
        exit 1
    fi
}

# æ‰§è¡Œä¸»æµç¨‹
main "$@"
```

#### ç¾éš¾æ¢å¤è®¡åˆ’

```bash
#!/bin/bash
# restore-n8n.sh - ç¾éš¾æ¢å¤è„šæœ¬

set -euo pipefail

BACKUP_FILE=$1
RECOVERY_TYPE=${2:-"full"}  # full, database, workflows, config
ENCRYPTION_KEY_FILE="/etc/n8n/backup.key"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# ä»äº‘å­˜å‚¨ä¸‹è½½å¤‡ä»½
download_backup() {
    local backup_name=$1
    log "ä»äº‘å­˜å‚¨ä¸‹è½½å¤‡ä»½: ${backup_name}"
    
    aws s3 cp "s3://${S3_BUCKET}/${backup_name}" "/tmp/${backup_name}"
    
    if [ ! -f "/tmp/${backup_name}" ]; then
        log "é”™è¯¯: å¤‡ä»½ä¸‹è½½å¤±è´¥"
        exit 1
    fi
}

# è§£å¯†å’Œè§£å‹å¤‡ä»½
extract_backup() {
    local backup_file=$1
    local extract_dir="/tmp/n8n-restore"
    
    log "è§£å¯†å’Œè§£å‹å¤‡ä»½..."
    
    # è§£å¯†
    openssl enc -aes-256-cbc -d \
        -in "${backup_file}" \
        -out "/tmp/backup.tar.gz" \
        -pass file:"${ENCRYPTION_KEY_FILE}"
    
    # è§£å‹
    mkdir -p "${extract_dir}"
    tar -xzf "/tmp/backup.tar.gz" -C "${extract_dir}" --strip-components=1
    
    echo "${extract_dir}"
}

# æ¢å¤æ•°æ®åº“
restore_database() {
    local backup_dir=$1
    log "å¼€å§‹æ•°æ®åº“æ¢å¤..."
    
    # åœæ­¢n8næœåŠ¡
    docker-compose down
    
    # å¤‡ä»½å½“å‰æ•°æ®åº“
    log "å¤‡ä»½å½“å‰æ•°æ®åº“..."
    PGPASSWORD=${DB_PASSWORD} pg_dump \
        -h ${DB_HOST} \
        -U ${DB_USER} \
        -d ${DB_NAME} \
        > "/tmp/current-db-backup-$(date +%Y%m%d%H%M%S).sql"
    
    # æ¢å¤æ•°æ®åº“
    log "æ¢å¤æ•°æ®åº“æ•°æ®..."
    gunzip -c "${backup_dir}/database.sql.gz" | \
    PGPASSWORD=${DB_PASSWORD} psql \
        -h ${DB_HOST} \
        -U ${DB_USER} \
        -d ${DB_NAME}
    
    log "æ•°æ®åº“æ¢å¤å®Œæˆ"
}

# æ¢å¤å·¥ä½œæµ
restore_workflows() {
    local backup_dir=$1
    log "å¼€å§‹å·¥ä½œæµæ¢å¤..."
    
    # å¯åŠ¨n8nï¼ˆå¦‚æœæœªè¿è¡Œï¼‰
    if ! docker-compose ps | grep -q "Up"; then
        docker-compose up -d
        sleep 30  # ç­‰å¾…æœåŠ¡å¯åŠ¨
    fi
    
    # å¯¼å…¥å·¥ä½œæµ
    docker cp "${backup_dir}/workflows-backup.json" n8n-main-1:/tmp/
    docker exec n8n-main-1 n8n import:workflow --input=/tmp/workflows-backup.json
    
    # å¯¼å…¥å‡­æ®æ¨¡æ¿
    docker cp "${backup_dir}/credentials-backup.json" n8n-main-1:/tmp/
    docker exec n8n-main-1 n8n import:credentials --input=/tmp/credentials-backup.json
    
    log "å·¥ä½œæµæ¢å¤å®Œæˆ"
}

# æ¢å¤é…ç½®
restore_config() {
    local backup_dir=$1
    log "å¼€å§‹é…ç½®æ¢å¤..."
    
    # å¤‡ä»½å½“å‰é…ç½®
    cp docker-compose.yml "docker-compose.yml.bak.$(date +%Y%m%d%H%M%S)"
    cp .env ".env.bak.$(date +%Y%m%d%H%M%S)"
    
    # æ¢å¤é…ç½®æ–‡ä»¶
    cp "${backup_dir}/docker-compose.yml" ./
    cp "${backup_dir}/.env" ./
    
    # æ¢å¤Nginxé…ç½®
    if [ -d "${backup_dir}/nginx" ]; then
        cp -r "${backup_dir}/nginx/" ./
    fi
    
    # æ¢å¤è‡ªå®šä¹‰èŠ‚ç‚¹
    if [ -d "${backup_dir}/custom-nodes" ]; then
        cp -r "${backup_dir}/custom-nodes/" ./
    fi
    
    log "é…ç½®æ¢å¤å®Œæˆ"
}

# éªŒè¯æ¢å¤
verify_recovery() {
    log "å¼€å§‹éªŒè¯æ¢å¤..."
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if ! docker-compose ps | grep -q "Up"; then
        log "å¯åŠ¨æœåŠ¡..."
        docker-compose up -d
        sleep 60
    fi
    
    # å¥åº·æ£€æŸ¥
    local health_check_attempts=0
    while [ $health_check_attempts -lt 30 ]; do
        if curl -f http://localhost:5678/healthz > /dev/null 2>&1; then
            log "n8næœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            break
        fi
        
        health_check_attempts=$((health_check_attempts + 1))
        log "ç­‰å¾…æœåŠ¡å¯åŠ¨... (${health_check_attempts}/30)"
        sleep 10
    done
    
    if [ $health_check_attempts -eq 30 ]; then
        log "é”™è¯¯: æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi
    
    # éªŒè¯æ•°æ®åº“è¿æ¥
    if docker exec n8n-main-1 n8n worker --help > /dev/null 2>&1; then
        log "æ•°æ®åº“è¿æ¥éªŒè¯é€šè¿‡"
    else
        log "é”™è¯¯: æ•°æ®åº“è¿æ¥éªŒè¯å¤±è´¥"
        return 1
    fi
    
    log "æ¢å¤éªŒè¯æˆåŠŸ"
    return 0
}

# ä¸»æ¢å¤æµç¨‹
main() {
    log "å¼€å§‹n8nç¾éš¾æ¢å¤æµç¨‹..."
    log "æ¢å¤ç±»å‹: ${RECOVERY_TYPE}"
    
    # ä¸‹è½½å¤‡ä»½æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯S3è·¯å¾„ï¼‰
    if [[ $BACKUP_FILE == s3://* ]]; then
        local backup_name=$(basename $BACKUP_FILE)
        download_backup $backup_name
        BACKUP_FILE="/tmp/${backup_name}"
    fi
    
    # è§£å‹å¤‡ä»½
    local backup_dir=$(extract_backup $BACKUP_FILE)
    
    # æ ¹æ®æ¢å¤ç±»å‹æ‰§è¡Œç›¸åº”æ“ä½œ
    case $RECOVERY_TYPE in
        "full")
            restore_database $backup_dir
            restore_workflows $backup_dir
            restore_config $backup_dir
            ;;
        "database")
            restore_database $backup_dir
            ;;
        "workflows")
            restore_workflows $backup_dir
            ;;
        "config")
            restore_config $backup_dir
            ;;
        *)
            log "é”™è¯¯: æœªçŸ¥æ¢å¤ç±»å‹ ${RECOVERY_TYPE}"
            exit 1
            ;;
    esac
    
    # éªŒè¯æ¢å¤
    if verify_recovery; then
        log "n8nç¾éš¾æ¢å¤å®Œæˆ"
        
        # å‘é€æˆåŠŸé€šçŸ¥
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"âœ… n8nç¾éš¾æ¢å¤æˆåŠŸå®Œæˆ\"}" \
            "${SLACK_WEBHOOK_URL}"
    else
        log "é”™è¯¯: ç¾éš¾æ¢å¤éªŒè¯å¤±è´¥"
        
        # å‘é€å¤±è´¥å‘Šè­¦
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"âŒ n8nç¾éš¾æ¢å¤å¤±è´¥\"}" \
            "${SLACK_WEBHOOK_URL}"
        
        exit 1
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -rf $backup_dir /tmp/backup.tar.gz
}

# å‚æ•°éªŒè¯
if [ $# -lt 1 ]; then
    echo "ç”¨æ³•: $0 <backup_file> [recovery_type]"
    echo "recovery_type: full|database|workflows|config (é»˜è®¤: full)"
    exit 1
fi

# æ‰§è¡Œä¸»æµç¨‹
main
```

é€šè¿‡å®æ–½è¿™äº›ä¼ä¸šçº§è¿ç»´å®è·µï¼Œæ‚¨å¯ä»¥ç¡®ä¿n8nåœ¨ä¼ä¸šç¯å¢ƒä¸­çš„é«˜å¯ç”¨æ€§ã€å®‰å…¨æ€§å’Œåˆè§„æ€§ï¼Œæ»¡è¶³ä¼ä¸šçº§åº”ç”¨çš„å„é¡¹è¦æ±‚ã€‚

---

## æ€»ç»“

æœ¬é«˜çº§å¼€å‘æŒ‡å—æ¶µç›–äº†n8nå¹³å°çš„æ·±åº¦æŠ€æœ¯è§£æã€è‡ªå®šä¹‰èŠ‚ç‚¹å¼€å‘ã€å¤æ‚å·¥ä½œæµè®¾è®¡æ¨¡å¼ã€æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§ï¼Œä»¥åŠä¼ä¸šçº§è¿ç»´å®è·µç­‰æ–¹é¢ã€‚é€šè¿‡æŒæ¡è¿™äº›é«˜çº§æŠ€æœ¯å’Œæœ€ä½³å®è·µï¼Œæ‚¨å¯ä»¥ï¼š

1. **æ·±å…¥ç†è§£n8næ¶æ„** - æŒæ¡å¹³å°æ ¸å¿ƒæ¦‚å¿µå’ŒæŠ€æœ¯åŸç†
2. **å¼€å‘é«˜è´¨é‡è‡ªå®šä¹‰èŠ‚ç‚¹** - æ‰©å±•å¹³å°åŠŸèƒ½æ»¡è¶³ç‰¹å®šéœ€æ±‚
3. **è®¾è®¡å¥å£®çš„å·¥ä½œæµ** - åº”ç”¨è®¾è®¡æ¨¡å¼æ„å»ºå¯é çš„è‡ªåŠ¨åŒ–æµç¨‹
4. **ä¼˜åŒ–æ€§èƒ½å’Œç›‘æ§** - ç¡®ä¿ç”Ÿäº§ç¯å¢ƒçš„ç¨³å®šè¿è¡Œ
5. **å®æ–½ä¼ä¸šçº§è¿ç»´** - æ»¡è¶³å®‰å…¨ã€åˆè§„å’Œå¯é æ€§è¦æ±‚

è¿™äº›æŠ€æœ¯å’Œå®è·µå°†å¸®åŠ©æ‚¨å……åˆ†å‘æŒ¥n8nçš„æ½œåŠ›ï¼Œæ„å»ºä¼ä¸šçº§çš„å·¥ä½œæµè‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆã€‚ 